# ---------------------------------------
#
#       Master thesis, 2016/2017
#     Tereza Stanglova, A14N0115P
#
# Network architecture - underfitting
# ---------------------------------------

# Constants
ImageWidth          = 64
ImageHeight         = 64
# ImageWidth        = 128  
# ImageHeight       = 128

NumberOfChannels        = 3
labelDim 	            = 2
mean                    = 128

# model
model = Sequential (
    ConvolutionalLayer { 16, (5:5), stride=(1:1), pad=false, init='normal', initValueScale=0.0043, initBias=1 } : ReLU :
    MaxPoolingLayer    { (2:2), stride=(2:2) } :
    ConvolutionalLayer { 32, (5:5), pad = true, init='normal', initValueScale=10, initBias=1 } : ReLU :
    MaxPoolingLayer    { (2:2), stride=(2:2) } :
    DenseLayer         { 128, activation=ReLU, init='normal', initValueScale=12, initBias=1 } : Dropout :
    LinearLayer        { labelDim, init='normal', initValueScale=0.01 }
)

# inputs
features = Input { ImageWidth : ImageHeight : NumberOfChannels }
featNorm = features - Constant ( mean )
labels = Input { labelDim }

# apply model to features
z = model (featNorm)

# loss and error computation
ce       = CrossEntropyWithSoftmax  (labels, z)
errs     = ClassificationError      (labels, z)
top5Errs = ClassificationError      (labels, z, topN=5)  # only used in Eval action

# declare special nodes
featureNodes    = (features)
labelNodes      = (labels)
criterionNodes  = (ce)
evaluationNodes = (errs)
outputNodes     = (z)